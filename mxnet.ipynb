{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import csv\n",
    "import collections\n",
    "# import get_secret\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Load settings from the deployment path or Default file\n",
    "config_path = \"config.json\"\n",
    "if os.path.exists(\"/config/camera_inference_config.json\"):\n",
    "    config_path = \"/config/camera_inference_config.json\"\n",
    "\n",
    "\n",
    "class StreamConfig(dict):\n",
    "\n",
    "    # deployment config path\n",
    "    DEFAULT_CONFIG_FILE = config_path\n",
    "    DEFAULT_CLASSES_FILE = \"classes.csv\"\n",
    "    DEFAULT_GSTREAMER_SRC = \"videotestsrc is-live=TRUE do-timestamp=TRUE ! video/x-raw, framerate=30/1, width=X, height=Y ! videoconvert ! timeoverlay ! appsink wait-on-eos=false max-buffers=1 drop=True\"\n",
    "    DEFAULT_GSTREAMER_DST = \"appsrc ! queue leaky=2 ! jpegenc ! tcpserversink host=0.0.0.0 port=X sync-method=0 recover-policy=0 sync=false\"\n",
    "    DETECTION_KEY = \"detection\"\n",
    "    SUBDETECTION_KEY = \"inner\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Default params\n",
    "        self.update(\n",
    "            {\n",
    "                \"id\": \"default\",\n",
    "                \"info\": {\"vehiclePlazaID\": \"0\", \"vehicleLaneID\": \"0\", \"vehiclePlazaName\": \"0\"},\n",
    "                \"source\": {\n",
    "                    \"name\": \"/video/ambulance.mp4\",\n",
    "                    \"type\": \"GSTREAMER\",  # FILE, RTSP, LIVE, GSTREAMER, RANDOM or TEST\n",
    "                    \"restart_on_failure\": True,\n",
    "                    \"ip\": None,\n",
    "                    \"port\": 554,\n",
    "                    \"username\": None,\n",
    "                    \"password\": None,\n",
    "                    \"width\": None,\n",
    "                    \"height\": None,\n",
    "                    \"fps\": 30,\n",
    "                    \"timeout_sec\": 5,\n",
    "                },\n",
    "                \"target\": {\n",
    "                    \"enabled\": False,\n",
    "                    \"filename\": None,\n",
    "                    \"gstreamer\": None,\n",
    "                    \"port\": None,\n",
    "                    \"width\": 1280,\n",
    "                    \"height\": 720,\n",
    "                    \"fps\": 30,\n",
    "                },\n",
    "                \"ml\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"model_dir\": \"/model/\",\n",
    "                    \"framework\": \"MXNET\",\n",
    "                    \"network\": \"model\",\n",
    "                    \"score_threshold\": 0.5,\n",
    "                    \"border_size\": 1,\n",
    "                    \"font_scale\": 0.5,\n",
    "                    \"device_type\": \"GPU\",\n",
    "                    \"input_shape\": [1, 3, 512, 512],\n",
    "                    \"select_top\": True,\n",
    "                    \"selected_classes\": None,  # List of class IDs\n",
    "                    \"subgroups\": [\"logo\", \"carplate\"],\n",
    "                    \"sort_by_coordinate\": [\n",
    "                        0,\n",
    "                        False,\n",
    "                    ],  # Cooridnates: [topLeft.x topLeft.y bottomRight.x bottomRight.y]\n",
    "                    \"draw_bounding_boxes\": False,\n",
    "                    \"lane_zone\": None,  # [[100, 700], [1200, 700], [1200, 1000], [100, 1000]]\n",
    "                    \"zone_point\": \"BOTTOM\",  # BOTTOM, LEFT, RIGHT, TOP, CENTER\n",
    "                },\n",
    "                \"tracker\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"max_age\": 1,\n",
    "                    \"min_hits\": 3,\n",
    "                    \"draw_bounding_box\": False,\n",
    "                },\n",
    "                \"voter\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"override_enabled\": False,\n",
    "                    \"send_top_classes\": False,\n",
    "                    \"overridden_classes\": [16, 17, 18, 19, 30, 31],\n",
    "                    \"buffer_size\": 10,\n",
    "                    \"threshold\": 1.0,\n",
    "                    \"draw_bounding_box\": False,\n",
    "                },\n",
    "                \"ocr\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"model_dir\": \"/data/ocr/\",\n",
    "                    \"send_carplateImage\": False,\n",
    "                    \"network\": \"ocr-net\",\n",
    "                },\n",
    "                \"upload\": {\n",
    "                    \"enabled\": False,\n",
    "                    \"topic\": None,\n",
    "                    \"save_carplateImage\": False,\n",
    "                    \"save_frame\": True,\n",
    "                    \"trigger\": \"push\",  # Keyword to be set in metadata on trigger\n",
    "                    \"stream\": \"inference_results\",\n",
    "                    \"max_size\": 512435456,  # Default is 512 MB\n",
    "                    \"stream_segment_size\": 64777216,  # Default is 64 MB.\n",
    "                    \"time_to_live_millis\": None,\n",
    "                    \"persistence\": \"Memory\",  # File or Memory\n",
    "                    \"jpeg_quality\": 50,\n",
    "                },\n",
    "                \"measure_fps\": False,\n",
    "                \"num_frames\": -1,\n",
    "                \"debug\": False,\n",
    "                \"log_interval\": 30,\n",
    "                \"debug_file\": \"/video/time_tracker.csv\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Set params from env variables\n",
    "        self[\"greengrass\"] = StreamConfig.IsGreengrassEnabled()\n",
    "\n",
    "        # Overwrite all default params with the input ones\n",
    "        if len(args) > 0:\n",
    "            self.update(StreamConfig.DeepUpdate(self, args[0]))\n",
    "\n",
    "        # Automatically enable FPS measurement for num_frames > 0\n",
    "        if self[\"num_frames\"] > 0:\n",
    "            self[\"measure_fps\"] = True\n",
    "\n",
    "        # Update some fields with default values if wrong input\n",
    "        if self.get(\"source.type\") == \"GSTREAMER\":\n",
    "            useDefault = True\n",
    "            if self.isSet(\"source.name\"):\n",
    "                if \"!\" in self.get(\"source.name\"):\n",
    "                    useDefault = False\n",
    "                if self.isSet(\"source.ip\"):\n",
    "                    try:\n",
    "                        credentials = get_secret()\n",
    "                        username = (\n",
    "                            f'{self.get(\"info.vehiclePlazaID\")}{self.get(\"info.vehicleLaneID\")}'\n",
    "                        )\n",
    "                        password = credentials[\"CAM_PASS\"]\n",
    "                        ip = self.get(\"source.ip\")\n",
    "                        port = self.get(\"source.port\")\n",
    "                        rtspUrl = \"rtsp://%s:%s@%s:%d\" % (username, password, ip, port)\n",
    "                        self[\"source\"][\n",
    "                            \"name\"\n",
    "                        ] = f\"rtspsrc location={rtspUrl} latency=0 ! queue ! rtph264depay ! decodebin ! videoconvert ! appsink sync=false\"\n",
    "                        useDefault = False\n",
    "                    except Exception as e:\n",
    "                        raise Exception(\"AWS secret manager not configured : \" + repr(e))\n",
    "            if useDefault:\n",
    "                gstSrc = StreamConfig.DEFAULT_GSTREAMER_SRC\n",
    "                gstSrc = gstSrc.replace(\"width=X\", \"width=%d\" % self.get(\"source.width\"))\n",
    "                gstSrc = gstSrc.replace(\"height=Y\", \"height=%d\" % self.get(\"source.height\"))\n",
    "                self[\"source\"][\"name\"] = gstSrc\n",
    "\n",
    "        # Update source field\n",
    "        if self.get(\"source.type\") == \"RTSP\":\n",
    "            try:\n",
    "                credentials = get_secret()\n",
    "                username = f'{self.get(\"info.vehiclePlazaID\")}{self.get(\"info.vehicleLaneID\")}'\n",
    "                password = credentials[\"CAM_PASS\"]\n",
    "                ip = self.get(\"source.ip\")\n",
    "                port = self.get(\"source.port\")\n",
    "                self[\"source\"][\"name\"] = \"rtsp://%s:%s@%s:%d\" % (username, password, ip, port)\n",
    "            except Exception as e:\n",
    "                raise Exception(\"AWS secret manager not configured : \" + repr(e))\n",
    "\n",
    "        # Update target fields\n",
    "        if self.isSet(\"target.port\"):\n",
    "            gstDst = StreamConfig.DEFAULT_GSTREAMER_DST\n",
    "            gstDst = gstDst.replace(\"port=X\", \"port=%d\" % self.get(\"target.port\"))\n",
    "            self[\"target\"][\"gstreamer\"] = gstDst\n",
    "\n",
    "        # Assume trigger on detection if trigger is None\n",
    "        if self.get(\"upload.trigger\") is None:\n",
    "            self[\"upload\"][\"trigger\"] = StreamConfig.DETECTION_KEY\n",
    "\n",
    "    @staticmethod\n",
    "    def DeepUpdate(original, update):\n",
    "        \"\"\"\n",
    "        Recursively update a dict. Subdicts won't be overwritten but also updated.\n",
    "        \"\"\"\n",
    "        if not isinstance(original, collections.Mapping):\n",
    "            return update\n",
    "        for key, value in update.items():\n",
    "            if isinstance(value, collections.Mapping):\n",
    "                original[key] = StreamConfig.DeepUpdate(original.get(key), value)\n",
    "            else:\n",
    "                original[key] = value\n",
    "        return original\n",
    "\n",
    "    def isGreengrassEnabled(self):\n",
    "        return self[\"greengrass\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def IsGreengrassEnabled():\n",
    "        for envvar in os.environ:\n",
    "            if envvar == \"AWS_GG_MQTT_ENDPOINT\":\n",
    "                return True\n",
    "            elif envvar == \"AWS_GG_HTTP_ENDPOINT\":\n",
    "                return True\n",
    "            elif envvar == \"AWS_GG_MQTT_PORT\":\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def LoadJSON(filename):\n",
    "        with open(filename) as json_file:\n",
    "            return json.load(json_file)\n",
    "\n",
    "    @staticmethod\n",
    "    def LoadCSV(filename):\n",
    "        with open(filename) as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            classes = {}\n",
    "            groups = {}\n",
    "            for i in reader:\n",
    "                classes[i[0]] = i[1]\n",
    "                groups[i[0]] = i[2]\n",
    "            return classes, groups  # a dictionary with values in tuple\n",
    "\n",
    "    @staticmethod\n",
    "    def LoadConfigFromFile(filename=None):\n",
    "        if filename is None:\n",
    "            filename = StreamConfig.DEFAULT_CONFIG_FILE\n",
    "        return StreamConfig.LoadJSON(filename)\n",
    "\n",
    "    @staticmethod\n",
    "    def LoadClassesFromFile(filename=None):\n",
    "        if filename is None:\n",
    "            filename = StreamConfig.DEFAULT_CLASSES_FILE\n",
    "        return StreamConfig.LoadCSV(filename)\n",
    "\n",
    "    @staticmethod\n",
    "    def __get(obj, key):\n",
    "        if type(key) is str:\n",
    "            chain = key.split(\".\")\n",
    "        else:\n",
    "            chain = key\n",
    "        _key = chain.pop(0)\n",
    "        if _key in obj:\n",
    "            return StreamConfig.__get(obj[_key], chain) if chain else obj[_key]\n",
    "        return None\n",
    "\n",
    "    def get(self, key):\n",
    "        return StreamConfig.__get(self, key)\n",
    "\n",
    "    def isSet(self, key):\n",
    "        found = self.get(key)\n",
    "        return found is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydarknet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4643ebeb32aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# from stream_config import StreamConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpydarknet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDetector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydarknet'"
     ]
    }
   ],
   "source": [
    "# from stream_config import StreamConfig\n",
    "import cv2\n",
    "from pydarknet import Detector, Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time_tracker import TimeTracker\n",
    "\n",
    "\n",
    "class OCR:\n",
    "    def __init__(self, config, time_tracker_config):\n",
    "        self.time_tracker = time_tracker_config[\"time_tracker\"]\n",
    "        self.num_frame = time_tracker_config[\"num_frame\"]\n",
    "        self.time_tracker_file = time_tracker_config[\"time_tracker_file\"]\n",
    "        self.enabled = config[\"enabled\"]\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        ocr_netcfg = \"{}{}.cfg\".format(config[\"model_dir\"], config[\"network\"])\n",
    "        ocr_weights = \"{}{}.weights\".format(config[\"model_dir\"], config[\"network\"])\n",
    "        ocr_dataset = \"{}{}.data\".format(config[\"model_dir\"], config[\"network\"])\n",
    "\n",
    "        if (\n",
    "            not os.path.exists(ocr_netcfg)\n",
    "            or not os.path.exists(ocr_weights)\n",
    "            or not os.path.exists(ocr_dataset)\n",
    "        ):\n",
    "            raise Exception(\n",
    "                \"Model files not found: %s, %s, %s\" % (ocr_netcfg, ocr_netcfg, ocr_dataset)\n",
    "            )\n",
    "\n",
    "        self.net = Detector(\n",
    "            bytes(ocr_netcfg, encoding=\"utf-8\"),\n",
    "            bytes(ocr_weights, encoding=\"utf-8\"),\n",
    "            0,\n",
    "            bytes(ocr_dataset, encoding=\"utf-8\"),\n",
    "        )\n",
    "\n",
    "        self.lp_image = None\n",
    "        self.save_carplate = config[\"send_carplateImage\"]\n",
    "\n",
    "    @TimeTracker\n",
    "    def rotate(self, image, angle, center=None, scale=1.0):\n",
    "        \"\"\"\n",
    "        This function take image and angle as input and return\n",
    "        rotated image as output\n",
    "        \"\"\"\n",
    "        (h, w) = image.shape[:2]\n",
    "        if center is None:\n",
    "            center = (w / 2, h / 2)\n",
    "\n",
    "        # Perform the rotation\n",
    "        M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "        return rotated\n",
    "\n",
    "    @TimeTracker\n",
    "    def carplate_rotation(self, image):\n",
    "        \"\"\"\n",
    "        This function take image as input, detect the angle and\n",
    "        return the rotated image\n",
    "        \"\"\"\n",
    "        src = image.copy()\n",
    "        scale = 1\n",
    "        delta = 0\n",
    "        ddepth = cv2.CV_16S\n",
    "\n",
    "        # Grayscale and Canny Edges extracted:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 100, 170, apertureSize=3)\n",
    "\n",
    "        try:\n",
    "            lines = cv2.HoughLines(edges, 1, (np.pi / 180) * 4, 20)\n",
    "            avg_theta = []\n",
    "            for line in lines[:5]:\n",
    "                for rho, theta in line:\n",
    "                    if theta * 180 / np.pi > 90 and theta * 180 / np.pi < 110:\n",
    "                        avg_theta.append(theta * 180 / np.pi)\n",
    "                        a = np.cos(theta)\n",
    "                        b = np.sin(theta)\n",
    "                        x0 = a * rho\n",
    "                        y0 = b * rho\n",
    "                        x1 = int(x0 + 1000 * (-b))\n",
    "                        y1 = int(y0 + 1000 * (a))\n",
    "                        x2 = int(x0 - 1000 * (-b))\n",
    "                        y2 = int(y0 - 1000 * (a))\n",
    "            img = self.rotate(src, np.mean(avg_theta) - 90, center=None, scale=1.0)\n",
    "\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            return image\n",
    "\n",
    "    @TimeTracker\n",
    "    def noise_removal(self, image):\n",
    "        se1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        se2 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        mask = cv2.morphologyEx(image, cv2.MORPH_CLOSE, se1)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, se2)\n",
    "        return mask\n",
    "\n",
    "    def histogram_equalization(self, img_in):\n",
    "        # segregate color streams\n",
    "        b, g, r = cv2.split(img_in)\n",
    "        h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
    "        h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
    "        h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
    "        # calculate cdf\n",
    "        cdf_b = np.cumsum(h_b)\n",
    "        cdf_g = np.cumsum(h_g)\n",
    "        cdf_r = np.cumsum(h_r)\n",
    "\n",
    "        # mask all pixels with value=0 and replace it with mean of the pixel values\n",
    "        cdf_m_b = np.ma.masked_equal(cdf_b, 0)\n",
    "        cdf_m_b = (cdf_m_b - cdf_m_b.min()) * 255 / (cdf_m_b.max() - cdf_m_b.min())\n",
    "        cdf_final_b = np.ma.filled(cdf_m_b, 0).astype(\"uint8\")\n",
    "\n",
    "        cdf_m_g = np.ma.masked_equal(cdf_g, 0)\n",
    "        cdf_m_g = (cdf_m_g - cdf_m_g.min()) * 255 / (cdf_m_g.max() - cdf_m_g.min())\n",
    "        cdf_final_g = np.ma.filled(cdf_m_g, 0).astype(\"uint8\")\n",
    "        cdf_m_r = np.ma.masked_equal(cdf_r, 0)\n",
    "        cdf_m_r = (cdf_m_r - cdf_m_r.min()) * 255 / (cdf_m_r.max() - cdf_m_r.min())\n",
    "        cdf_final_r = np.ma.filled(cdf_m_r, 0).astype(\"uint8\")\n",
    "        # merge the images in the three channels\n",
    "        img_b = cdf_final_b[b]\n",
    "        img_g = cdf_final_g[g]\n",
    "        img_r = cdf_final_r[r]\n",
    "\n",
    "        img_out = cv2.merge((img_b, img_g, img_r))\n",
    "        # validation\n",
    "        equ_b = cv2.equalizeHist(b)\n",
    "        equ_g = cv2.equalizeHist(g)\n",
    "        equ_r = cv2.equalizeHist(r)\n",
    "        equ = cv2.merge((equ_b, equ_g, equ_r))\n",
    "        return img_out\n",
    "\n",
    "    @TimeTracker\n",
    "    def contour_image(self, image):\n",
    "        \"\"\"\n",
    "        This function take license plate image as input and return only text portion\n",
    "        of license plate image as output\n",
    "        \"\"\"\n",
    "\n",
    "        img = self.carplate_rotation(image)\n",
    "        imw, imh = img.shape[:2]\n",
    "\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray = cv2.GaussianBlur(img_gray, (3, 3), 0)\n",
    "\n",
    "        simg = cv2.Sobel(img_gray, -1, 1, 0)\n",
    "        _, bw = cv2.threshold(simg, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "        bw = self.noise_removal(bw)\n",
    "\n",
    "        se = cv2.getStructuringElement(cv2.MORPH_RECT, (int(imw / 4), 4))\n",
    "        mimg = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, se)\n",
    "\n",
    "        contours, _ = cv2.findContours(mimg, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "        chunks = []\n",
    "\n",
    "        for i, c in enumerate(contours):\n",
    "            # Calculate the area of each contour\n",
    "            area = cv2.contourArea(c)\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            if w / h > 0.4 and w * h > imw * imh * 0.04:\n",
    "                chunks.append([x, y, x + w, y + h])\n",
    "        # img = self.histogram_equalization(img)\n",
    "        if len(chunks) == 1:\n",
    "            w_ = chunks[0][2] - chunks[0][0]\n",
    "            h_ = chunks[0][3] - chunks[0][1]\n",
    "            x1 = max(chunks[0][0] - int(w_ * 0.1), 0)\n",
    "            y1 = max(chunks[0][1] - int(h_ * 0.1), 0)\n",
    "            x2 = min(chunks[0][2] + int(w_ * 0.1), imh)\n",
    "            y2 = min(chunks[0][3] + int(h_ * 0.1), imw)\n",
    "\n",
    "            return img[y1:y2, x1:x2]\n",
    "\n",
    "        elif len(chunks) > 1:\n",
    "            w_ = max([i[2] for i in chunks]) - min([i[0] for i in chunks])\n",
    "            h_ = max([i[3] for i in chunks]) - min([i[1] for i in chunks])\n",
    "            x1 = max(min([i[0] for i in chunks]) - int(w_ * 0.1), 0)\n",
    "            y1 = max(min([i[1] for i in chunks]) - int(h_ * 0.1), 0)\n",
    "            x2 = min(max([i[2] for i in chunks]) + int(w_ * 0.1), imh)\n",
    "            y2 = min(max([i[3] for i in chunks]) + int(h_ * 0.1), imw)\n",
    "\n",
    "            return img[y1:y2, x1:x2]\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    @TimeTracker\n",
    "    def cropLpWithMargin(self, frame, params):\n",
    "        duplicate_frame = frame.copy()\n",
    "        W, H = duplicate_frame.shape[:2]\n",
    "        box = params[\"inner\"][\"carplate\"].bounding_box\n",
    "        x1 = box[0]\n",
    "        y1 = box[1]\n",
    "        x2 = box[2]\n",
    "        y2 = box[3]\n",
    "        h = y2 - y1\n",
    "        w = x2 - x1\n",
    "        lpx1 = max(int(x1 - (w * 0.2)), 0)\n",
    "        lpx2 = min(int(x2 + (w * 0.2)), H)\n",
    "        lpy1 = max(int(y1 - (h * 0.2)), 0)\n",
    "        lpy2 = min(int(y2 + (h * 0.2)), W)\n",
    "        carplate_frame = duplicate_frame[lpy1:lpy2, lpx1:lpx2]\n",
    "        return carplate_frame\n",
    "\n",
    "    def get_sequence_data(self, data):\n",
    "        df = data.sort_values(by=[\"centery\"])\n",
    "        lst = list(df[\"centery\"])\n",
    "        count = 0\n",
    "        line = []\n",
    "        for i in range(len(lst)):\n",
    "            if i != len(lst) - 1:\n",
    "                if lst[i + 1] - lst[i] > 8:\n",
    "                    line.append(count)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    line.append(count)\n",
    "            else:\n",
    "                line.append(count)\n",
    "        df[\"line\"] = line\n",
    "        df = df.sort_values(by=[\"line\", \"centerx\"])\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "\n",
    "    @TimeTracker\n",
    "    def Image_to_string(self, img_path):\n",
    "        \"\"\"\n",
    "        This function lp image as input and return recognition results\n",
    "        as output\n",
    "        \"\"\"\n",
    "        img_darknet = Image(img_path)\n",
    "\n",
    "        results = self.net.detect(img_darknet, thresh=0.5, nms=0.25)\n",
    "        if len(results):\n",
    "            dct = {\n",
    "                \"centerx\": [int(i[2][0] + i[2][2] / 2) for i in results],\n",
    "                \"centery\": [int(i[2][1] + i[2][3] / 2) for i in results],\n",
    "                \"text\": [str(i[0].decode(\"utf-8\")) for i in results],\n",
    "            }\n",
    "            lp_str = \"\".join(self.get_sequence_data(pd.DataFrame(dct))[\"text\"])\n",
    "        else:\n",
    "            lp_str = \"-\"\n",
    "        return lp_str\n",
    "\n",
    "    @TimeTracker\n",
    "    def process(self, frame, params):\n",
    "        if not self.enabled:\n",
    "            params[\"LP\"] = \"None\"\n",
    "            return params\n",
    "\n",
    "        lp = params[StreamConfig.SUBDETECTION_KEY][\"carplate\"]\n",
    "\n",
    "        if lp is not None:\n",
    "            original_img = self.cropLpWithMargin(frame, params)\n",
    "            cropped_img = self.contour_image(original_img)\n",
    "            carplate_number = self.Image_to_string(cropped_img)\n",
    "            if len(carplate_number) >= 3:\n",
    "                params[\"LP\"] = carplate_number.replace(\"I\", \"1\").replace(\"O\", \"0\")\n",
    "                self.lp_image = original_img\n",
    "            else:\n",
    "                self.lp_image = None\n",
    "        if self.save_carplate:\n",
    "            params[\"lp_image\"] = self.lp_image\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
