{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'new.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whitening import whiten\n",
    "from PIL import Image\n",
    "from PIL import ImageChops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(path)\n",
    "image, background = whiten(image, kernel_size=20, downsample=5)\n",
    "image = ImageChops.subtract(image,background)\n",
    "mask1 = Image.eval(image, lambda a: 0 if a <= 24 else 255)\n",
    "mask2 = mask1.convert('1')\n",
    "\n",
    "blank = Image.eval(image, lambda a: 0)\n",
    "\n",
    "new = Image.composite(background, blank, mask2) \n",
    "# new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.save('test.png','PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tesseract without any segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Process begin .....\n"
     ]
    }
   ],
   "source": [
    "from tesserocr import PyTessBaseAPI , RIL\n",
    "import tesserocr\n",
    "img=Image.open(path)\n",
    "img=img.resize((200,200))\n",
    "api = PyTessBaseAPI(lang='eng')\n",
    "api.SetImage(img)\n",
    "print ( \"OCR Process begin .....\")\n",
    "# start_time = time.time()\n",
    "api.SetVariable(\"tessedit_char_whitelist\", \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\")\n",
    "b = api.GetUTF8Text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract with PSM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Process begin .....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['=']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=Image.open(path)\n",
    "# img=img.resize((400,200))\n",
    "api = PyTessBaseAPI(lang='eng', psm=5)\n",
    "api.SetImage(img)\n",
    "print ( \"OCR Process begin .....\")\n",
    "# start_time = time.time()\n",
    "api.SetVariable(\"tessedit_char_whitelist\", \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\")\n",
    "b = str(api.GetUTF8Text()).splitlines()\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract with image RIL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 textline image components.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tesserocr import PyTessBaseAPI, RIL\n",
    "\n",
    "image = Image.open(path)\n",
    "with PyTessBaseAPI() as api:\n",
    "    api.SetImage(image)\n",
    "    boxes = api.GetComponentImages(RIL.PARA, True)\n",
    "    print('Found {} textline image components.'.format(len(boxes)))\n",
    "    for i, (im, box, _, _) in enumerate(boxes):\n",
    "        # im is a PIL image object\n",
    "        # box is a dict with x, y, w and h keys\n",
    "        api.SetRectangle(box['x'], box['y'], box['w'], box['h'])\n",
    "        ocrResult = api.GetUTF8Text()\n",
    "        conf = api.MeanTextConf()\n",
    "        print(u\"Box[{0}]: x={x}, y={y}, w={w}, h={h}, \"\n",
    "              \"confidence: {1}, text: {2}\".format(i, conf, ocrResult, **box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No text returned",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-7be013df8816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSYMBOL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msymbol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetUTF8Text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# r == ri\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfidence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtesserocr.pyx\u001b[0m in \u001b[0;36mtesserocr._tesserocr.PyLTRResultIterator.GetUTF8Text\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No text returned"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tesserocr import PyTessBaseAPI, RIL, iterate_level\n",
    "\n",
    "with PyTessBaseAPI() as api:\n",
    "    api.SetImageFile(path)\n",
    "    api.SetVariable(\"save_blob_choices\", \"T\")\n",
    "    api.SetRectangle(50, 50 , 121, 186)\n",
    "    api.Recognize()\n",
    "\n",
    "    ri = api.GetIterator()\n",
    "    level = RIL.SYMBOL\n",
    "    for r in iterate_level(ri, level):\n",
    "        symbol = r.GetUTF8Text(level)  # r == ri\n",
    "        conf = r.Confidence(level)\n",
    "        if symbol:\n",
    "            print(u'symbol {}, conf: {}'.format(symbol, conf), end='')\n",
    "        indent = False\n",
    "        ci = r.GetChoiceIterator()\n",
    "        for c in ci:\n",
    "            if indent:\n",
    "                print('\\t\\t ', end='')\n",
    "            print('\\t- ', end='')\n",
    "            choice = c.GetUTF8Text()  # c == ci\n",
    "            print(u'{} conf: {}'.format(choice, c.Confidence()))\n",
    "            indent = True\n",
    "        print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read image\n",
    "import cv2\n",
    "img = cv2.imread(r\"D:\\tapway\\Plate_detect_and_recognize\\testcase\\cropped-lp1-20200715-104932371Z.jpg\")\n",
    "\n",
    "#grayscale\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#binarize \n",
    "ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#find contours\n",
    "ctrs, hier = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, \n",
    "cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#sort contours\n",
    "sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "for i, ctr in enumerate(sorted_ctrs):\n",
    "    # Get bounding box\n",
    "    x, y, w, h = cv2.boundingRect(ctr)\n",
    "\n",
    "    # Getting ROI\n",
    "    roi = img[y:y+h, x:x+w]\n",
    "\n",
    "    # show ROI\n",
    "    #cv2.imwrite('roi_imgs.png', roi)\n",
    "    cv2.imshow('charachter'+str(i), roi)\n",
    "    cv2.rectangle(img,(x,y),( x + w, y + h ),(90,0,255),2)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('marked areas',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(r\"D:\\tapway\\testcase\\cropped-lp1-20200715-110252772Z.jpg\", 0)\n",
    "cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU,img)\n",
    "contours, hier = cv2.findContours(img, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "cv2.imshow(\"contours\", img)\n",
    "cv2.waitKey(0)\n",
    "d=0\n",
    "for ctr in contours:\n",
    "    # Get bounding box\n",
    "    x, y, w, h = cv2.boundingRect(ctr)\n",
    "    # Getting ROI\n",
    "    roi = img[y:y+h, x:x+w]\n",
    "\n",
    "    cv2.imshow('character: %d'%d,roi)\n",
    "    cv2.imwrite('character_%d.png'%d, roi)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    d+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
